{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7706238,"sourceType":"datasetVersion","datasetId":4499158},{"sourceId":7920171,"sourceType":"datasetVersion","datasetId":4654154},{"sourceId":7921109,"sourceType":"datasetVersion","datasetId":4654871},{"sourceId":7923952,"sourceType":"datasetVersion","datasetId":4656847},{"sourceId":7924892,"sourceType":"datasetVersion","datasetId":4657491},{"sourceId":7925088,"sourceType":"datasetVersion","datasetId":4657620},{"sourceId":7927134,"sourceType":"datasetVersion","datasetId":4658864},{"sourceId":7930287,"sourceType":"datasetVersion","datasetId":4661209},{"sourceId":7930370,"sourceType":"datasetVersion","datasetId":4661268}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-24T14:48:35.320236Z","iopub.execute_input":"2024-03-24T14:48:35.320946Z","iopub.status.idle":"2024-03-24T14:48:35.350488Z","shell.execute_reply.started":"2024-03-24T14:48:35.320901Z","shell.execute_reply":"2024-03-24T14:48:35.349540Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"/kaggle/input/model-ac/model_ac.pkl\n/kaggle/input/testmulti/finalTestMultiScale.txt\n/kaggle/input/model-ab/model_ab.pkl\n/kaggle/input/finaltestmultiscale-r-3/finalTestMultiScale r_3- Cloud.txt\n/kaggle/input/model-ad/model_ad.pkl\n/kaggle/input/0-25a-split/0.25a/NoNan0.25aa_part_ac.txt\n/kaggle/input/0-25a-split/0.25a/NoNan0.25aa_part_ae.txt\n/kaggle/input/0-25a-split/0.25a/NoNan0.25aa_part_af.txt\n/kaggle/input/0-25a-split/0.25a/NoNan0.25aa_part_ad.txt\n/kaggle/input/0-25a-split/0.25a/NoNan0.25aa_part_aa.txt\n/kaggle/input/0-25a-split/0.25a/NoNan0.25aa_part_ab.txt\n/kaggle/input/0-25ab/0.25aa.txt\n/kaggle/input/multiscale-r-3/multiScale_r_3 - Cloud.txt\n/kaggle/input/model-a/model_a.pkl\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score ","metadata":{"execution":{"iopub.status.busy":"2024-03-24T14:48:35.352365Z","iopub.execute_input":"2024-03-24T14:48:35.353261Z","iopub.status.idle":"2024-03-24T14:48:35.358777Z","shell.execute_reply.started":"2024-03-24T14:48:35.353212Z","shell.execute_reply":"2024-03-24T14:48:35.357511Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import resample\n\ndef load_data(filename):\n     # Read the first line to get the column names and set desired feature order\n    with open(filename, 'r') as file:\n        column_names = file.readline().strip().split()\n    column_names[0] = 'X'\n\n    feature_order = [\n    'X', 'Y', 'Z', 'R', 'G', 'B', \n    'Planarity_(0.1)', 'Linearity_(0.1)', 'PCA1_(0.1)', 'Sphericity_(0.1)', 'Verticality_(0.1)', '1st_eigenvalue_(0.1)',\n    'Planarity_(0.125)', 'Linearity_(0.125)', 'PCA1_(0.125)', 'Sphericity_(0.125)', 'Verticality_(0.125)', '1st_eigenvalue_(0.125)',\n    'Sphericity_(0.25)', 'Verticality_(0.25)', '1st_eigenvalue_(0.25)',\n    'Planarity_(0.5)', 'Linearity_(0.5)', 'PCA1_(0.5)', 'Sphericity_(0.5)', 'Verticality_(0.5)', '1st_eigenvalue_(0.5)',\n    'Planarity_(1)', 'Linearity_(1)', 'PCA1_(1)', 'Sphericity_(1)', 'Verticality_(1)', '1st_eigenvalue_(1)',\n    '3rd_eigenvalue_(2)', 'Linearity_(2)', 'PCA1_(2)', 'Sphericity_(2)', 'Verticality_(2)', '1st_eigenvalue_(2)', '2nd_eigenvalue_(2)',\n    'Planarity_(3)', 'Linearity_(3)', 'PCA1_(3)', 'Sphericity_(3)', 'Verticality_(3)', '1st_eigenvalue_(3)', '2nd_eigenvalue_(3)', '3rd_eigenvalue_(3)'\n    ]\n\n    max_points_per_class = 200000\n    # Read the data skipping the first line\n    data = np.genfromtxt(filename, skip_header=1)\n    \n    # Remove rows with NaN values\n    data = data[~np.isnan(data).any(axis=1)]\n#     correlation_matrix = data.corr()\n\n#     # Print the correlation matrix\n#     print(correlation_matrix)\n    \n#     plt.figure(figsize=(10, 8))\n#     sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n#     plt.title('Correlation Matrix of Features')\n#     plt.show()\n\n    # Reorder the features based on the desired order\n    feature_indices = [column_names.index(feature) for feature in feature_order[:]]  # Exclude 'Classification'\n    features = data[:, feature_indices]\n    \n    # Extract labels\n    label_index = column_names.index('Classification')\n    labels = data[:, label_index].astype(int)\n    \n    # Perform class balancing with maximum points per class\n    class_counts = Counter(labels)\n    balanced_features = []\n    balanced_labels = []\n    for cls, count in class_counts.items():\n        cls_features = features[labels == cls]\n        cls_labels = np.full((count,), cls, dtype=int)\n        if count > max_points_per_class:\n            # Downsample majority class\n            cls_features_resampled = resample(cls_features, n_samples=max_points_per_class, replace=False, random_state=42)\n            cls_labels_resampled = resample(cls_labels, n_samples=max_points_per_class, replace=False, random_state=42)\n            balanced_features.append(cls_features_resampled)\n            balanced_labels.append(cls_labels_resampled)\n        else:\n            balanced_features.append(cls_features)\n            balanced_labels.append(cls_labels)\n    \n    balanced_features = np.concatenate(balanced_features)\n    balanced_labels = np.concatenate(balanced_labels)\n    \n    # Print class counts\n    print(\"Class Counts:\")\n    for cls, count in sorted(class_counts.items()):\n        print(f\"Class {cls}: {count}\")\n    \n    # Print balanced label counts\n    balanced_label_counts = Counter(balanced_labels)\n    print(\"\\nBalanced Label Counts:\")\n    for cls, count in sorted(balanced_label_counts.items()):\n        print(f\"Class {cls}: {count}\")\n    \n    return balanced_features, balanced_labels\n\nfilename = '/kaggle/input/multiscale-r-3/multiScale_r_3 - Cloud.txt' \npoints, labels = load_data(filename)\nnum_classes = len(np.unique(labels))\n\nprint(\"Total number of classes:\", num_classes)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-24T14:48:35.360771Z","iopub.execute_input":"2024-03-24T14:48:35.361544Z","iopub.status.idle":"2024-03-24T14:53:11.017972Z","shell.execute_reply.started":"2024-03-24T14:48:35.361503Z","shell.execute_reply":"2024-03-24T14:53:11.016584Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Class Counts:\nClass 0: 1629365\nClass 1: 224671\nClass 2: 45141\nClass 3: 112805\nClass 4: 642025\nClass 5: 147937\nClass 6: 46888\nClass 7: 438052\nClass 9: 18636\nClass 10: 2861\n\nBalanced Label Counts:\nClass 0: 200000\nClass 1: 200000\nClass 2: 45141\nClass 3: 112805\nClass 4: 200000\nClass 5: 147937\nClass 6: 46888\nClass 7: 200000\nClass 9: 18636\nClass 10: 2861\nTotal number of classes: 10\n","output_type":"stream"}]},{"cell_type":"code","source":"# print(points[11])","metadata":{"execution":{"iopub.status.busy":"2024-03-24T14:53:11.021141Z","iopub.execute_input":"2024-03-24T14:53:11.021567Z","iopub.status.idle":"2024-03-24T14:53:11.026369Z","shell.execute_reply.started":"2024-03-24T14:53:11.021528Z","shell.execute_reply":"2024-03-24T14:53:11.025261Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"nan_rows = np.any(np.isnan(points), axis=1)\nnum_nan_rows = np.sum(nan_rows)\n\nprint(f\"Number of rows containing NaN values: {num_nan_rows}\")\ntotal_rows = points.shape[0]\nprint(f\"Total number of rows: {total_rows}\")\nprint(f\"Total number of labels\",labels.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T14:53:11.027629Z","iopub.execute_input":"2024-03-24T14:53:11.028525Z","iopub.status.idle":"2024-03-24T14:53:11.145808Z","shell.execute_reply.started":"2024-03-24T14:53:11.028488Z","shell.execute_reply":"2024-03-24T14:53:11.144561Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Number of rows containing NaN values: 0\nTotal number of rows: 1174268\nTotal number of labels (1174268,)\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(points, labels, test_size=0.2, random_state=42)\n\n# Initialize Random Forest classifier\nrandom_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the classifier\nrandom_forest.fit(X_train, y_train)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-24T14:53:11.147227Z","iopub.execute_input":"2024-03-24T14:53:11.147634Z","iopub.status.idle":"2024-03-24T15:20:37.926390Z","shell.execute_reply.started":"2024-03-24T14:53:11.147597Z","shell.execute_reply":"2024-03-24T15:20:37.924975Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier(random_state=42)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"# from joblib import load\n\n# # Load the model from the .pkl file\n# random_forest = load('/kaggle/input/model-ad/model_ad.pkl')\n# random_forest.fit(points,labels)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T15:20:37.928817Z","iopub.execute_input":"2024-03-24T15:20:37.929249Z","iopub.status.idle":"2024-03-24T15:20:37.935982Z","shell.execute_reply.started":"2024-03-24T15:20:37.929209Z","shell.execute_reply":"2024-03-24T15:20:37.934565Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Predict on the test set\ny_pred = random_forest.predict(X_test)\ny_pred\n","metadata":{"execution":{"iopub.status.busy":"2024-03-24T15:20:37.937766Z","iopub.execute_input":"2024-03-24T15:20:37.938618Z","iopub.status.idle":"2024-03-24T15:20:45.151187Z","shell.execute_reply.started":"2024-03-24T15:20:37.938580Z","shell.execute_reply":"2024-03-24T15:20:45.149690Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"array([1, 6, 0, ..., 4, 5, 7])"},"metadata":{}}]},{"cell_type":"code","source":"# # Predict on the test set\n# y_pred = random_forest.predict(points)\n# y_pred\n","metadata":{"execution":{"iopub.status.busy":"2024-03-24T15:20:45.152899Z","iopub.execute_input":"2024-03-24T15:20:45.153299Z","iopub.status.idle":"2024-03-24T15:20:45.158026Z","shell.execute_reply.started":"2024-03-24T15:20:45.153261Z","shell.execute_reply":"2024-03-24T15:20:45.157052Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Calculate accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T15:20:45.162224Z","iopub.execute_input":"2024-03-24T15:20:45.163062Z","iopub.status.idle":"2024-03-24T15:20:45.190977Z","shell.execute_reply.started":"2024-03-24T15:20:45.163013Z","shell.execute_reply":"2024-03-24T15:20:45.189734Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Accuracy: 0.9923186320011582\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Calculate accuracy\n# accuracy = accuracy_score(labels, y_pred)\n# print(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T15:20:45.192766Z","iopub.execute_input":"2024-03-24T15:20:45.193536Z","iopub.status.idle":"2024-03-24T15:20:45.198934Z","shell.execute_reply.started":"2024-03-24T15:20:45.193459Z","shell.execute_reply":"2024-03-24T15:20:45.197512Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import joblib\njoblib.dump(random_forest, 'r_3.pkl')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-24T15:20:45.200863Z","iopub.execute_input":"2024-03-24T15:20:45.201874Z","iopub.status.idle":"2024-03-24T15:20:46.736303Z","shell.execute_reply.started":"2024-03-24T15:20:45.201834Z","shell.execute_reply":"2024-03-24T15:20:46.734771Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"['r_3.pkl']"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nfrom collections import Counter\nfrom sklearn.utils import resample\n\ndef load_testData(filename):\n     # Read the first line to get the column names and set desired feature order\n    with open(filename, 'r') as file:\n        column_names = file.readline().strip().split()\n    column_names[0] = 'X'\n\n    feature_order = [\n    'X', 'Y', 'Z', 'R', 'G', 'B', \n    'Planarity_(0.1)', 'Linearity_(0.1)', 'PCA1_(0.1)', 'Sphericity_(0.1)', 'Verticality_(0.1)', '1st_eigenvalue_(0.1)',\n    'Planarity_(0.125)', 'Linearity_(0.125)', 'PCA1_(0.125)', 'Sphericity_(0.125)', 'Verticality_(0.125)', '1st_eigenvalue_(0.125)',\n    'Sphericity_(0.25)', 'Verticality_(0.25)', '1st_eigenvalue_(0.25)',\n    'Planarity_(0.5)', 'Linearity_(0.5)', 'PCA1_(0.5)', 'Sphericity_(0.5)', 'Verticality_(0.5)', '1st_eigenvalue_(0.5)',\n    'Planarity_(1)', 'Linearity_(1)', 'PCA1_(1)', 'Sphericity_(1)', 'Verticality_(1)', '1st_eigenvalue_(1)',\n    '3rd_eigenvalue_(2)', 'Linearity_(2)', 'PCA1_(2)', 'Sphericity_(2)', 'Verticality_(2)', '1st_eigenvalue_(2)', '2nd_eigenvalue_(2)',\n    'Planarity_(3)', 'Linearity_(3)', 'PCA1_(3)', 'Sphericity_(3)', 'Verticality_(3)', '1st_eigenvalue_(3)', '2nd_eigenvalue_(3)', '3rd_eigenvalue_(3)'\n    ]\n\n    max_points_per_class = 200000\n    # Read the data skipping the first line\n    data = np.genfromtxt(filename, skip_header=1)\n    \n    # Remove rows with NaN values\n    data = data[~np.isnan(data).any(axis=1)]\n    \n    # Reorder the features based on the desired order\n    feature_indices = [column_names.index(feature) for feature in feature_order[:]]  # Exclude 'Classification'\n    features = data[:, feature_indices]\n    \n    # Extract labels\n    label_index = column_names.index('Classification')\n    labels = data[:, label_index].astype(int)\n    \n    return features,labels\n \n\n# filename = '/kaggle/input/multiscale/multiScale.txt' \n# points, labels = load_data(filename)\n# num_classes = len(np.unique(labels))\n\n# print(\"Total number of classes:\", num_classes)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-24T15:20:46.738369Z","iopub.execute_input":"2024-03-24T15:20:46.738938Z","iopub.status.idle":"2024-03-24T15:20:46.753333Z","shell.execute_reply.started":"2024-03-24T15:20:46.738895Z","shell.execute_reply":"2024-03-24T15:20:46.751744Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"points,labels = load_testData('/kaggle/input/finaltestmultiscale-r-3/finalTestMultiScale r_3- Cloud.txt')","metadata":{"execution":{"iopub.status.busy":"2024-03-24T15:20:46.755735Z","iopub.execute_input":"2024-03-24T15:20:46.756348Z","iopub.status.idle":"2024-03-24T15:24:25.955093Z","shell.execute_reply.started":"2024-03-24T15:20:46.756297Z","shell.execute_reply":"2024-03-24T15:24:25.953625Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Predict on the test set\ny_pred = random_forest.predict(points)\ny_pred\n","metadata":{"execution":{"iopub.status.busy":"2024-03-24T15:24:25.956929Z","iopub.execute_input":"2024-03-24T15:24:25.957563Z","iopub.status.idle":"2024-03-24T15:25:24.003335Z","shell.execute_reply.started":"2024-03-24T15:24:25.957526Z","shell.execute_reply":"2024-03-24T15:25:24.001583Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"array([5, 5, 5, ..., 0, 0, 0])"},"metadata":{}}]},{"cell_type":"code","source":"# Calculate accuracy\naccuracy = accuracy_score(labels, y_pred)\nprint(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T15:25:24.005362Z","iopub.execute_input":"2024-03-24T15:25:24.005841Z","iopub.status.idle":"2024-03-24T15:25:24.126992Z","shell.execute_reply.started":"2024-03-24T15:25:24.005797Z","shell.execute_reply":"2024-03-24T15:25:24.126056Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Accuracy: 0.7271925943912426\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\nf1 = f1_score(labels, y_pred, average='weighted')  \nprint(\"F1-score:\", f1)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T15:25:24.128180Z","iopub.execute_input":"2024-03-24T15:25:24.129333Z","iopub.status.idle":"2024-03-24T15:25:24.967457Z","shell.execute_reply.started":"2024-03-24T15:25:24.129263Z","shell.execute_reply":"2024-03-24T15:25:24.966248Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"F1-score: 0.6932256286494846\n","output_type":"stream"}]},{"cell_type":"code","source":"def save_data(points, predicted_labels, filename):\n    with open(filename, 'w') as file:\n        # Write comment line with column names\n        file.write(\"// X Y Z R G B predictedClassification\\n\")\n        # Write data lines\n        for i in range(len(points)):\n            point = points[i][:6]\n            predicted_label = predicted_labels[i]\n            data_str = ' '.join([str(coord) for coord in point]) + f' {predicted_label}\\n'\n            file.write(data_str)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T15:25:26.232359Z","iopub.execute_input":"2024-03-24T15:25:26.233501Z","iopub.status.idle":"2024-03-24T15:25:26.240525Z","shell.execute_reply.started":"2024-03-24T15:25:26.233445Z","shell.execute_reply":"2024-03-24T15:25:26.239632Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"save_data(points, y_pred, \"r_3_Final_model_result.txt\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-24T15:25:26.241933Z","iopub.execute_input":"2024-03-24T15:25:26.242795Z","iopub.status.idle":"2024-03-24T15:25:46.981880Z","shell.execute_reply.started":"2024-03-24T15:25:26.242761Z","shell.execute_reply":"2024-03-24T15:25:46.980566Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}